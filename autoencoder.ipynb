{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import spektral\n",
    "from spektral.utils import normalized_laplacian, rescale_laplacian\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import Isomap\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def set_mpl_style():\n",
    "    plt.rcParams.update({\n",
    "        \"figure.dpi\": 300,\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"lines.linewidth\": 1.0,\n",
    "        \"lines.markersize\": 2,\n",
    "        \"xtick.direction\": \"out\",\n",
    "        \"ytick.direction\": \"out\",\n",
    "        \"xtick.major.size\": 4,\n",
    "        \"ytick.major.size\": 4,\n",
    "        \"xtick.major.width\": 0.8,\n",
    "        \"ytick.major.width\": 0.8,\n",
    "        \"xtick.minor.visible\": True,\n",
    "        \"ytick.minor.visible\": True,\n",
    "        \"legend.frameon\": True,\n",
    "        \"axes.grid\": False,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.format\": \"pdf\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "    })\n",
    "    \n",
    "class CheckpointCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, ckpt_manager):\n",
    "        super().__init__()\n",
    "        self.ckpt_manager = ckpt_manager\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        save_path = self.ckpt_manager.save()\n",
    "        print(f'\\nsaved checkpoint for epoch {epoch + 1}: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots and visualizations\n",
    "\n",
    "def plot_events(events, title='hit_pattern', subtitles=[]):\n",
    "    assert len(events.shape) == 4, 'Events must be a 3D array with shape (num_events, num_rows * num_cols, num_samples)'\n",
    "    events = np.transpose(events, axes=[3, 0, 1, 2])\n",
    "\n",
    "    gif_frames = []\n",
    "    for sample in tqdm(events):\n",
    "        num_events = sample.shape[0]\n",
    "        fig, ax = plt.subplots(1, num_events, figsize=(3*num_events, 3), dpi=100)\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "\n",
    "        if num_events == 1: ax = [ax]\n",
    "\n",
    "        for i, hit_pattern in enumerate(sample):\n",
    "            ax[i].imshow(hit_pattern, vmin=0, vmax=5)\n",
    "            ax[i].set_xticks([])\n",
    "            ax[i].set_yticks([])\n",
    "            ax[i].grid(False)\n",
    "            \n",
    "            if len(subtitles) >= i + 1:\n",
    "                ax[i].set_title(subtitles[i], fontsize=8)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        width, height = fig.get_size_inches() * fig.dpi\n",
    "        data = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "        image_array = data.reshape(int(height), int(width), 4)\n",
    "\n",
    "        image_frame = Image.fromarray(image_array)\n",
    "        gif_frames.append(image_frame)\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "    filename = re.sub(r'[^a-zA-Z0-9]', '', title.lower()) + '_gif.gif'\n",
    "    gif_frames[0].save(\n",
    "        filename,\n",
    "        save_all = True,\n",
    "        duration = 20,\n",
    "        loop = 0,\n",
    "        append_images = gif_frames[1:]\n",
    "    )\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def vis_latent_space_categories(data_categories, data_categories_labels, title):\n",
    "    # plt.rcParams['figure.dpi'] = 120\n",
    "    \n",
    "    for data, label in zip(data_categories, data_categories_labels):\n",
    "        plt.scatter(data[:, 0], data[:, 1], label=label, s=0.5)\n",
    "    \n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.savefig(re.sub(r'[^a-zA-Z0-9]', '', title.lower()) + '.png')\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "def vis_latent_space_gradients(latent_space, labels, title, colorbar_label):\n",
    "    # plt.rcParams['figure.dpi'] = 120\n",
    "    \n",
    "    plt.scatter(latent_space[:, 0], latent_space[:, 1], c=labels, cmap='viridis', s=0.5)\n",
    "    plt.title(title)\n",
    "    plt.colorbar().set_label(colorbar_label)\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.savefig(re.sub(r'[^a-zA-Z0-9]', '', title.lower()) + '.png')\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "\n",
    "def vis_latent_space_num_scatters(fit_model, latent_space, Y, N=4):\n",
    "    num_scatters = np.where(Y > 0, 1, 0).sum(axis=(1, 2))\n",
    "    \n",
    "    num_sactters_categories = [latent_space[np.where(num_scatters == i)] for i in range(1, N + 1)]\n",
    "    num_scatters_labels = [f'{i} scatter' + ('s' if i > 1 else '') for i in range(1, N + 1)]\n",
    "    \n",
    "    vis_latent_space_categories(num_sactters_categories, num_scatters_labels, f'Autoencoder Latent Space by Number of Scatters {type(fit_model).__name__.upper()}')\n",
    "\n",
    "\n",
    "def vis_latent_space_phd(fit_model, latent_space, XC):\n",
    "    phd = XC.sum(axis=(1, 2))\n",
    "    vis_latent_space_gradients(latent_space, phd, f'Autoencoder Latent Space by Total Photoelectrons Deposited {type(fit_model).__name__.upper()}', colorbar_label='phd')\n",
    "    \n",
    "def vis_latent_space_footprint(fit_model, latent_space, XC):\n",
    "    footprint = np.where(XC.sum(axis=-1) > 4, 1, 0).sum(axis=-1)\n",
    "    \n",
    "    vis_latent_space_gradients(latent_space, footprint, f'Autoencoder Latent Space by Footprint Size {type(fit_model).__name__.upper()}', colorbar_label='Total # PMT')\n",
    "    \n",
    "\n",
    "def codebook_usage_histogram(vqvae, XC):\n",
    "    indices = vqvae.encode_to_indices_probabilistic(XC).numpy().flatten().astype(int)\n",
    "    codebook_usage = np.bincount(indices, minlength=vqvae.num_embeddings)\n",
    "    codebook_usage_sorted = codebook_usage[np.argsort(codebook_usage)[::-1]] / codebook_usage.sum()\n",
    "\n",
    "    # plt.rcParams['figure.dpi'] = 120\n",
    "    \n",
    "    plt.fill_between(np.arange(len(codebook_usage_sorted)), codebook_usage_sorted, color='blue', alpha=0.3)\n",
    "    plt.plot(np.arange(len(codebook_usage_sorted)), codebook_usage_sorted, color='blue', label='Usage')\n",
    "\n",
    "    plt.xlabel('Codebook Index')\n",
    "    plt.ylabel('Usage (PDF)')\n",
    "    plt.title('VQ-VAE Codebook Usage Distribution')\n",
    "    plt.margins(0)\n",
    "    plt.savefig('codebook_usage.png')\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def get_encoded_data_generator(compression_func, data_generator):\n",
    "    while True:\n",
    "        XC, XYZ, P = next(iter(data_generator))\n",
    "        XC_encoded = compression_func(XC)\n",
    "        yield XC_encoded, XYZ, P\n",
    "\n",
    "def run_aux_task(models, compression_funcs, labels, data_generator, val_data_generator, fname_suffix=''):\n",
    "    def precompute_batches(generator, steps):\n",
    "        return [next(generator) for _ in tqdm(range(steps))]\n",
    "\n",
    "    def train_epoch(model, train_batches, desc=''):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_batches, desc=desc, ncols=100):\n",
    "            x, y, _ = batch\n",
    "            loss = model.step(x, y, training=True)\n",
    "            if isinstance(loss, (list, tuple)):\n",
    "                loss = loss[0]\n",
    "            total_loss += loss\n",
    "        return total_loss\n",
    "\n",
    "    def test_epoch(model, val_batches):\n",
    "        total_loss = 0.0\n",
    "        for batch in val_batches:\n",
    "            x, y, _ = batch\n",
    "            loss = model.step(x, y, training=False)\n",
    "            if isinstance(loss, (list, tuple)):\n",
    "                loss = loss[0]\n",
    "            total_loss += loss\n",
    "        return total_loss\n",
    "    \n",
    "    def train_and_plot_model(model, compression_func, data_generator, val_data_generator, epochs=10, steps_per_epoch=64, val_steps=4):\n",
    "        if compression_func is not None:\n",
    "            data_generator = get_encoded_data_generator(compression_func, data_generator)\n",
    "            val_data_generator = get_encoded_data_generator(compression_func, val_data_generator)\n",
    "        \n",
    "        initial_val_loss = test_epoch(model, precompute_batches(val_data_generator, val_steps)) / val_steps\n",
    "        \n",
    "        train_times, val_losses = [0], [initial_val_loss]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_batches = precompute_batches(data_generator, steps_per_epoch)\n",
    "            val_batches = precompute_batches(data_generator, val_steps)\n",
    "            \n",
    "            desc = f'epoch {epoch + 1}/{epochs} ({model.name})'\n",
    "            t0 = time.time()\n",
    "            loss = train_epoch(model, train_batches, desc=desc)\n",
    "            train_time = time.time() - t0\n",
    "            avg_loss = loss / steps_per_epoch\n",
    "            avg_val_loss = test_epoch(model, val_batches) / val_steps\n",
    "            print(desc + f' - loss: {avg_loss:.3f}, val_loss: {avg_val_loss:.3f}')\n",
    "            \n",
    "            train_times.append(train_time)\n",
    "            val_losses.append(avg_val_loss)\n",
    "                \n",
    "        K.clear_session()\n",
    "            \n",
    "        cdf_train_times = [sum(train_times[:i + 1]) for i in range(len(train_times))]\n",
    "        best_val_losses = [min(val_losses[:i + 1]) for i in range(len(val_losses))]\n",
    "            \n",
    "        return cdf_train_times, best_val_losses\n",
    "    \n",
    "    epochs = 50\n",
    "    steps_per_epoch = 64\n",
    "    val_steps = 8\n",
    "            \n",
    "    model_cdf_train_times, model_best_val_losses = [], []\n",
    "    \n",
    "    for model, compression_func in zip(models, compression_funcs):\n",
    "        cdf_train_times, best_val_losses = train_and_plot_model(model, compression_func, data_generator, val_data_generator, epochs=epochs, steps_per_epoch=steps_per_epoch, val_steps=val_steps)\n",
    "        model_cdf_train_times.append(cdf_train_times)\n",
    "        model_best_val_losses.append(best_val_losses)\n",
    "    \n",
    "    sample_batch, _, _ = next(iter(data_generator))\n",
    "    batch_size = sample_batch.shape[0]\n",
    "    \n",
    "    plt.figure()\n",
    "    epochs_axis = np.arange(0, epochs + 1) * steps_per_epoch * batch_size\n",
    "    for label, val_losses in zip(labels, model_best_val_losses):\n",
    "        plt.plot(epochs_axis, val_losses, '-o', label=label, markersize=2)\n",
    "    plt.xlabel('Training Samples')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Sample Efficiency: Validation Loss (Best) vs Training Samples')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'raw_vs_compressed_sample_efficiency{fname_suffix}.png')\n",
    "    \n",
    "    plt.figure()\n",
    "    for label, cdf_train_times, val_losses in zip(labels, model_cdf_train_times, model_best_val_losses):\n",
    "        plt.plot(cdf_train_times, val_losses, '-o', label=label, markersize=2)\n",
    "    plt.xlabel('Training Time (s)')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Time Efficiency: Validation Loss (Best) vs Training Time')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'raw_vs_compressed_time_efficiency{fname_suffix}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder base class\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='Encoder')\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, name='encoder'):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "    \n",
    "    def call(self, x):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, x):\n",
    "        pass\n",
    "    \n",
    "    def decode(self, x):\n",
    "        pass\n",
    "    \n",
    "    def compress(self, x):\n",
    "        pass\n",
    "    \n",
    "    def get_data_size_reduction(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='Autoencoder')\n",
    "class Autoencoder(Encoder):\n",
    "    def __init__(self, input_shape, latent_dim, encoder_layer_sizes=[], decoder_layer_sizes=[], name='autoencoder'):\n",
    "        super(Autoencoder, self).__init__(name=name)\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.encoder_layer_sizes = encoder_layer_sizes\n",
    "        self.decoder_layer_sizes = decoder_layer_sizes\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Input(input_shape)] +\n",
    "            [tf.keras.layers.Flatten()] +\n",
    "            [tf.keras.layers.Dense(sz, activation='relu') for sz in encoder_layer_sizes] +\n",
    "            [tf.keras.layers.Dense(latent_dim)], name=f'{name}_encoder'\n",
    "        )\n",
    "    \n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Input((latent_dim,))] +\n",
    "            [tf.keras.layers.Dense(sz, activation='relu') for sz in decoder_layer_sizes] +\n",
    "            [tf.keras.layers.Dense(np.prod(input_shape), activation='softplus'),\n",
    "             tf.keras.layers.Reshape(input_shape)], name=f'{name}_decoder'\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def compress(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def compile(self, optimizer, loss, metrics=[]):\n",
    "        super().compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        \n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "    \n",
    "    def from_config(self, config):\n",
    "        return Autoencoder(**config)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'input_shape': self.input_shape,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'encoder_layer_sizes': self.encoder_layer_sizes,\n",
    "            'decoder_layer_sizes': self.decoder_layer_sizes\n",
    "        }\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def get_data_size_reducton(self):\n",
    "        return np.prod(self.input_shape) / self.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational Autoencoder\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='VariationalAutoencoder')\n",
    "class VariationalAutoencoder(Autoencoder):\n",
    "    def __init__(self, input_shape, latent_dim, encoder_layer_sizes=[], decoder_layer_sizes=[], name='variational_autoencoder'):\n",
    "        super(VariationalAutoencoder, self).__init__(input_shape, latent_dim, encoder_layer_sizes, decoder_layer_sizes, name)\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Input(input_shape)] +\n",
    "            [tf.keras.layers.Flatten()] +\n",
    "            [tf.keras.layers.Dense(sz, activation='relu') for sz in encoder_layer_sizes] +\n",
    "            [tf.keras.layers.Dense(latent_dim * 2)], name=f'{name}_encoder'  # output mean & log_var\n",
    "        )\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Input((latent_dim,))] +\n",
    "            [tf.keras.layers.Dense(sz, activation='relu') for sz in decoder_layer_sizes] +\n",
    "            [tf.keras.layers.Dense(np.prod(input_shape), activation='softplus'),\n",
    "             tf.keras.layers.Reshape(input_shape)], name=f'{name}_decoder'\n",
    "        )\n",
    "        \n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name='reconstruction_loss')\n",
    "    \n",
    "    def reparameterize(self, mean, log_var):\n",
    "        epsilon = tf.random.normal(shape=tf.shape(mean))\n",
    "        return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    def encode(self, x):\n",
    "        encoder_output = self.encoder(x)\n",
    "        mean, log_var = tf.split(encoder_output, num_or_size_splits=2, axis=-1)\n",
    "        return mean, log_var\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed, mean, log_var\n",
    "    \n",
    "    def compress(self, x):\n",
    "        encoder_output = self.encoder(x)\n",
    "        mean, log_var = tf.split(encoder_output, num_or_size_splits=2, axis=-1)\n",
    "        \n",
    "        # check this\n",
    "        eps = tf.random.normal(shape=tf.shape(mean))\n",
    "        sigma = tf.exp(0.5 * log_var)\n",
    "        sample = mean + sigma * eps\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x = data[0]\n",
    "        x = tf.cast(x, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed, mean, log_var = self(x, training=True)\n",
    "            loss = vae_loss(x, reconstructed, mean, log_var)\n",
    "            r_loss = reconstruction_loss(x, reconstructed)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.reconstruction_loss_tracker.update_state(r_loss)\n",
    "        \n",
    "        return {'loss': self.loss_tracker.result(), 'reconstruction_loss': self.reconstruction_loss_tracker.result()} \n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data[0]\n",
    "        x = tf.cast(x, tf.float32)\n",
    "\n",
    "        reconstructed, mean, log_var = self(x, training=False)\n",
    "        loss = vae_loss(x, reconstructed, mean, log_var)\n",
    "        r_loss = reconstruction_loss(x, reconstructed)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.reconstruction_loss_tracker.update_state(r_loss)\n",
    "        \n",
    "        return {'loss': self.loss_tracker.result(), 'reconstruction_loss': self.reconstruction_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.reconstruction_loss_tracker]\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(self, config):\n",
    "        return VariationalAutoencoder(**config)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'input_shape': self.input_shape,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'encoder_layer_sizes': self.encoder_layer_sizes,\n",
    "            'decoder_layer_sizes': self.decoder_layer_sizes\n",
    "        }\n",
    "        \n",
    "    def get_data_size_reduction(self):\n",
    "        return np.prod(self.input_shape) / (self.latent_dim * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
